---
layout: post
title: 使用Selenium翻页爬取数据
tags: [Python爬虫, Selenium]
excerpt_separator: <!--more-->
---
当网站采用了异步加载数据或者其他的一些反爬措施的时候，python爬虫常用的一些包比如BeautifulSoup，用起来就不是很方便了，这时候选择使用Selenium模拟浏览器环境来抓取数据。

<!--more-->
首先使用python模拟浏览器环境：

    >url = '需要爬取的页面url'
    >driver = webdriver.Chrome()
    >driver.get(url)

这样就可以在driver这个selenium类对象中，用[find_element_by_的一系列方法](http://selenium-python.readthedocs.io/locating-elements.html)来读取网页代码中的内容了，经过实测，有以下需要注意的几点：

### 一.确定网页代码
此时的driver包含所需要爬的网页的所有数据，但可能和实际线上的网页代码有细微差别，以本地抓取的driver对象的内容为准，在本地使用chrome查看driver对象的网页代码后，用find_element_by_class_name方法定位要抓取的元素。

### 二.实现网页翻页
当抓取完第一页的内容，需要翻页抓取第二页的内容，此时可以先定位到元素，再使用Selenium中的click方法来翻页获取新一页的内容

找到网页下方<下一页>元素的类名，在我爬取的网页中，当页面最下方的下一页可以点击的时候，检查页面代码，此时下一页按钮的类名为“pager_next”

而在最后一页中，下一页的按钮会变成灰色，且类名也变为"pager_next pager_next_disabled"，我们正好将这一变化作为整个爬取过程的结束节点：我们猜想当在最后一页定位类名为“pager_next”的方法时，会出现异常，所以我们采用try except来主动捕获异常退出循环完成爬取，避免程序异常退出。

第一版的代码如下：

    next_icon = driver.find_element_by_class_name('pager_next')
    now = 1
    while next_icon:
         print('The current page is:  ', now)
         try:        
              next_icon.click()
              collet_from_one_page(driver)
              now += 1
              print(‘After click, the current page is: ’, now)
              next_icon = driver.find_element_by_class_name('pager_next')
              print('a loop finished')          
         except :
              break

但发现，还没click到最后一页的下一页，expect就捕捉到异常导致循环break了，这时候我们通过每次click之后打印当前的页的“current_page”class，我们发现，有时候next_icon.click()执行过后，current_page并没有变化。

发现了这个问题后，通过搜索，在[stackoverflow上发现了类似的问题](https://stackoverflow.com/questions/11908249/debugging-element-is-not-clickable-at-point-error):

根据Stack Overflow上这个类似问题的最高赞答案我们可以分析出：
首先，该答案提到的第一个可能导致问题的原因：元素invisible，在此处并不适用，通过selenium打开的浏览器测试页面，该元素是无论在代码中还是页面上都是可见的。
那么再看下面的两个可能导致错误的原因：1.在执行click的时候，页面还在加载中未完全加载出来。2.click按钮上有蒙层元素，需要等待其消失。
而这两个原因共同的解决方式都是需要在click操作执行前等待一会儿，那么我们再在click操作的前面加上一句time.sleep(5)，等待5秒钟，运行看看是否能有改进。

### 三.处理最后一页

运行结果发现，虽然click操作能够顺利执行了，但是，在最后一页的时候，我们预估的本应该出现异常的这句代码：

>next_icon = driver.find_element_by_class_name('pager_next')

却没有出现异常，代码跑最后一页的这个地方时，依然可以继续。我怀疑是不是虽然最后一页中<下一页>按钮的类名为"pager_next pager_next_disabled"，但页面中也可能出现其他类名为“pager_next”的元素，阻止了异常的抛出，但经过在网页代码中搜索，发现这个原因并不成立。继续猜测，因为类名“pager_next”是“pager_next pager_next_disabled"的子序列，所以selenium的find_element_by_class_name在定位元素的时候依然可以定位到这个<下一页>的按钮。

有了上面的猜想，通过搜索，我发现，最后一页中class类名为"pager_next pager_next_disable"，这个类名中间的空格并不是空字符串，那是间隔符号，表示的是一个元素有多个class的名称(class属性是比较特殊的一个，除了这个有多个名称外，其它的像name,id是没多个名称的)

在find_element的时候只需要传入间隔符号前后的任意属性即可定位到该元素。

这个背景知识验证了我们上面的猜想，也就是说，在这一系列页面的所有页面中定位类名为"pager_next"的元素，是都不会出现异常的，但是，在下一页按钮clickable的情况下，在网页中定位”pager_next_disable”元素会出现异常。

那么我们的代码需要做一点改进：

    next_icon = driver.find_element_by_class_name('pager_next')
    now = 1
    while next_icon:
         print('The current page is:  ', now)
         try:
              last_icon = driver.find_element_by_class_name('pager_next_disabled')
              break
         except :
              time.sleep(5)
              next_icon.click()
              collet_from_one_page(driver)
              now += 1
              print(‘After click, the current page is: ’, now)
              next_icon = driver.find_element_by_class_name('pager_next')
              print('a loop finished')


### 四.等待页面加载

改进之后，从代码运行的结果来看，所有的print('a loop finished')都执行完毕了，我们的翻页功能问题得到了解决。

但是又出现了新的问题：在执行collet_from_one_page(driver)这个爬取页面内容的函数时，出现了第二页爬取的内容和第一页相同的问题。

回想我们在第二部分中遇到的问题：执行click操作的时候，当前网页还没有完全加载完从而引发异常。于是猜想，这里的问题是否也是因为第二页没有加载完成，内容提取的代码却已经开始运行，导致爬取第二页内容的时候，爬下来的内容却是第一页的。有了这样的猜想，我尝试了和第二部分的问题类似的解决办法，在执行collet_from_one_page(driver)函数之前，等待5秒钟让页面加载完毕：

    next_icon = driver.find_element_by_class_name('pager_next')
    now = 1
    while next_icon:
         print('The current page is:  ', now)
         try:
              last_icon = driver.find_element_by_class_name('pager_next_disabled')
              break
         except :
              time.sleep(5)
              next_icon.click()
              time.sleep(5)
              collet_from_one_page(driver)
              now += 1
              print(‘After click, the current page is: ’, now)
              next_icon = driver.find_element_by_class_name('pager_next')
              print('a loop finished')

sleep之后再运行，问题解决了！

但这只是一个最粗糙的临时解决方案，下一节我们可以研究一下selenium的内部线程，思考一下如何更精确地使页面加载完成，以及开始爬取内容，这两个任务能够同步，以更高效地解决这个问题，而不是简单粗暴地sleep10秒钟。









